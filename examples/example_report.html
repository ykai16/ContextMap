<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ContextMap ‚Äî Project Evolution</title>
  <style>
    *,
    *::before,
    *::after {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    :root {
      --bg: #1a1a1a;
      --bg-elevated: #222222;
      --surface: #2a2a2a;
      --surface-border: rgba(255, 255, 255, 0.07);
      --text-primary: #e8e4df;
      --text-secondary: #a09a92;
      --text-muted: #6b6560;
      --accent: #d4a27f;
      --accent-dim: rgba(212, 162, 127, 0.12);
      --accent-border: rgba(212, 162, 127, 0.2);
      --success: #6ec89b;
      --success-dim: rgba(110, 200, 155, 0.12);
      --warning: #e0b861;
      --warning-dim: rgba(224, 184, 97, 0.12);
      --error: #e07a6e;
      --error-dim: rgba(224, 122, 110, 0.12);
      --info: #7aade0;
      --info-dim: rgba(122, 173, 224, 0.12);
      --radius: 10px;
    }

    body {
      background: var(--bg);
      color: var(--text-primary);
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Helvetica Neue", sans-serif;
      font-size: 15px;
      line-height: 1.7;
      -webkit-font-smoothing: antialiased;
    }

    .container {
      max-width: 880px;
      margin: 0 auto;
      padding: 32px 24px 80px;
    }

    /* ‚îÄ‚îÄ‚îÄ Typography ‚îÄ‚îÄ‚îÄ */
    .serif {
      font-family: Georgia, "Times New Roman", "Noto Serif", serif;
    }

    code {
      font-family: "SF Mono", "Fira Code", Consolas, monospace;
      font-size: 0.88em;
      background: rgba(212, 162, 127, 0.08);
      padding: 1px 5px;
      border-radius: 3px;
      color: var(--accent);
    }

    /* ‚îÄ‚îÄ‚îÄ Header ‚îÄ‚îÄ‚îÄ */
    header {
      padding: 56px 0 40px;
      border-bottom: 1px solid var(--surface-border);
    }

    .logo {
      font-family: Georgia, "Times New Roman", serif;
      font-size: 36px;
      font-weight: 400;
      color: var(--text-primary);
      letter-spacing: -0.5px;
    }

    .logo span {
      color: var(--accent);
    }

    .header-sub {
      color: var(--text-muted);
      font-size: 14px;
      margin-top: 6px;
      font-weight: 400;
    }

    .meta-bar {
      display: flex;
      gap: 20px;
      margin-top: 16px;
      flex-wrap: wrap;
    }

    .meta-pill {
      font-size: 12px;
      color: var(--text-secondary);
      background: var(--surface);
      padding: 4px 12px;
      border-radius: 100px;
      border: 1px solid var(--surface-border);
    }

    /* ‚îÄ‚îÄ‚îÄ Sections ‚îÄ‚îÄ‚îÄ */
    section {
      margin-top: 48px;
    }

    .section-label {
      font-size: 11px;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 1.8px;
      color: var(--accent);
      margin-bottom: 12px;
    }

    .section-title {
      font-family: Georgia, "Times New Roman", serif;
      font-size: 22px;
      font-weight: 400;
      color: var(--text-primary);
      margin-bottom: 20px;
    }

    /* ‚îÄ‚îÄ‚îÄ Card ‚îÄ‚îÄ‚îÄ */
    .card {
      background: var(--bg-elevated);
      border: 1px solid var(--surface-border);
      border-radius: var(--radius);
      padding: 24px 28px;
    }

    /* ‚îÄ‚îÄ‚îÄ Narrative (bullet style) ‚îÄ‚îÄ‚îÄ */
    .narrative-session {
      margin-bottom: 20px;
    }

    .narrative-session:last-child {
      margin-bottom: 0;
    }

    .narrative-session-label {
      font-size: 13px;
      font-weight: 600;
      color: var(--accent);
      margin-bottom: 8px;
    }

    .narrative-list {
      list-style: none;
      padding: 0;
    }

    .narrative-list li {
      position: relative;
      padding: 4px 0 4px 22px;
      color: var(--text-secondary);
      font-size: 14px;
      line-height: 1.65;
    }

    .narrative-list li::before {
      content: "‚Ä¢";
      position: absolute;
      left: 4px;
      color: var(--accent);
      font-weight: bold;
    }

    /* ‚îÄ‚îÄ‚îÄ Anchor (icon-rich) ‚îÄ‚îÄ‚îÄ */
    .anchor-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 14px;
    }

    .anchor-item {
      display: flex;
      gap: 12px;
      padding: 14px 16px;
      background: var(--surface);
      border-radius: 8px;
      border: 1px solid var(--surface-border);
    }

    .anchor-icon {
      font-size: 20px;
      flex-shrink: 0;
      width: 28px;
      text-align: center;
      line-height: 1.4;
    }

    .anchor-label {
      font-size: 11px;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.8px;
      color: var(--text-muted);
      margin-bottom: 3px;
    }

    .anchor-text {
      font-size: 13px;
      color: var(--text-secondary);
      line-height: 1.55;
    }

    .anchor-item.full-width {
      grid-column: 1 / -1;
    }

    /* ‚îÄ‚îÄ‚îÄ Timeline ‚îÄ‚îÄ‚îÄ */
    .timeline {
      position: relative;
      padding-left: 28px;
    }

    .timeline::before {
      content: "";
      position: absolute;
      left: 8px;
      top: 8px;
      bottom: 8px;
      width: 1px;
      background: var(--surface-border);
    }

    .session-divider {
      position: relative;
      margin: 28px 0 20px -28px;
      padding-left: 28px;
    }

    .session-divider-label {
      font-size: 11px;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 1.5px;
      color: var(--accent);
      background: var(--bg);
      display: inline-block;
      padding-right: 12px;
      position: relative;
      z-index: 1;
    }

    .session-divider::after {
      content: "";
      position: absolute;
      left: 28px;
      right: 0;
      top: 50%;
      height: 1px;
      background: var(--accent-border);
      z-index: 0;
    }

    /* Step card */
    .step-card {
      position: relative;
      margin-bottom: 8px;
      cursor: pointer;
      background: var(--bg-elevated);
      border: 1px solid var(--surface-border);
      border-radius: var(--radius);
      padding: 20px 24px;
      transition: border-color 0.2s ease;
    }

    .step-card:hover {
      border-color: rgba(255, 255, 255, 0.12);
    }

    .step-dot {
      position: absolute;
      left: -23px;
      top: 26px;
      width: 9px;
      height: 9px;
      border-radius: 50%;
      z-index: 2;
    }

    .step-dot.success {
      background: var(--success);
    }

    .step-dot.partial {
      background: var(--warning);
    }

    .step-dot.failed {
      background: var(--error);
    }

    .step-dot.in_progress {
      background: var(--info);
    }

    .step-header {
      display: flex;
      align-items: center;
      gap: 10px;
      flex-wrap: wrap;
    }

    .step-num {
      font-size: 12px;
      color: var(--text-muted);
      font-variant-numeric: tabular-nums;
    }

    .step-title {
      font-family: Georgia, "Times New Roman", serif;
      font-size: 16px;
      font-weight: 400;
      color: var(--text-primary);
    }

    .badge {
      font-size: 10px;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.6px;
      padding: 2px 8px;
      border-radius: 100px;
    }

    .badge.success {
      background: var(--success-dim);
      color: var(--success);
    }

    .badge.partial {
      background: var(--warning-dim);
      color: var(--warning);
    }

    .badge.failed {
      background: var(--error-dim);
      color: var(--error);
    }

    .badge.in_progress {
      background: var(--info-dim);
      color: var(--info);
    }

    .step-preview {
      margin-top: 8px;
      font-size: 13px;
      color: var(--text-muted);
      line-height: 1.5;
      display: -webkit-box;
      -webkit-line-clamp: 2;
      -webkit-box-orient: vertical;
      line-clamp: 2;
      overflow: hidden;
    }

    .step-preview.hidden {
      display: none;
    }

    .step-detail {
      margin-top: 16px;
      display: none;
    }

    .step-detail.open {
      display: block;
    }

    .detail-section {
      margin-bottom: 14px;
    }

    .detail-section:last-child {
      margin-bottom: 0;
    }

    .detail-heading {
      font-size: 11px;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.8px;
      color: var(--accent);
      margin-bottom: 6px;
    }

    .detail-bullets {
      list-style: none;
      padding: 0;
    }

    .detail-bullets li {
      position: relative;
      padding: 2px 0 2px 16px;
      font-size: 13px;
      color: var(--text-secondary);
      line-height: 1.6;
    }

    .detail-bullets li::before {
      content: "‚Äì";
      position: absolute;
      left: 0;
      color: var(--text-muted);
    }

    .artifacts-row {
      display: flex;
      flex-wrap: wrap;
      gap: 5px;
      margin-top: 4px;
    }

    .artifact {
      font-size: 11px;
      font-family: "SF Mono", "Fira Code", Consolas, monospace;
      padding: 2px 8px;
      border-radius: 4px;
      background: var(--accent-dim);
      color: var(--accent);
      border: 1px solid var(--accent-border);
    }

    /* Transition */
    .transition {
      margin: 4px 0 8px 0;
      padding: 10px 16px;
      border-left: 2px solid var(--accent-border);
      margin-left: 4px;
    }

    .transition-text {
      font-size: 12px;
      color: var(--text-muted);
      font-style: italic;
      line-height: 1.55;
    }

    .transition-text::before {
      content: "‚Üì ";
      color: var(--accent);
    }

    /* ‚îÄ‚îÄ‚îÄ Open Threads ‚îÄ‚îÄ‚îÄ */
    .thread {
      display: flex;
      gap: 14px;
      padding: 16px 0;
      border-bottom: 1px solid var(--surface-border);
    }

    .thread:last-child {
      border-bottom: none;
    }

    .thread-icon {
      font-size: 18px;
      flex-shrink: 0;
      padding-top: 1px;
    }

    .thread-title {
      font-size: 14px;
      font-weight: 600;
      color: var(--text-primary);
      margin-bottom: 2px;
    }

    .thread-desc {
      font-size: 13px;
      color: var(--text-secondary);
      line-height: 1.55;
    }

    .thread-next {
      font-size: 12px;
      color: var(--accent);
      margin-top: 5px;
    }

    /* ‚îÄ‚îÄ‚îÄ Footer ‚îÄ‚îÄ‚îÄ */
    footer {
      margin-top: 64px;
      padding: 24px 0;
      border-top: 1px solid var(--surface-border);
      text-align: center;
    }

    footer p {
      font-size: 12px;
      color: var(--text-muted);
    }

    /* ‚îÄ‚îÄ‚îÄ Animations ‚îÄ‚îÄ‚îÄ */
    @keyframes fadeIn {
      from {
        opacity: 0;
        transform: translateY(10px);
      }

      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    .anim {
      opacity: 0;
      animation: fadeIn 0.4s ease forwards;
    }

    .d1 {
      animation-delay: 0.05s;
    }

    .d2 {
      animation-delay: 0.10s;
    }

    .d3 {
      animation-delay: 0.15s;
    }

    .d4 {
      animation-delay: 0.20s;
    }

    .d5 {
      animation-delay: 0.25s;
    }

    .d6 {
      animation-delay: 0.30s;
    }

    .d7 {
      animation-delay: 0.35s;
    }

    .d8 {
      animation-delay: 0.40s;
    }

    .d9 {
      animation-delay: 0.45s;
    }

    .d10 {
      animation-delay: 0.50s;
    }

    .d11 {
      animation-delay: 0.55s;
    }

    .d12 {
      animation-delay: 0.60s;
    }

    .d13 {
      animation-delay: 0.65s;
    }

    .d14 {
      animation-delay: 0.70s;
    }

    /* ‚îÄ‚îÄ‚îÄ Responsive ‚îÄ‚îÄ‚îÄ */
    @media (max-width: 640px) {
      .container {
        padding: 16px 16px 48px;
      }

      header {
        padding: 32px 0 24px;
      }

      .logo {
        font-size: 28px;
      }

      .anchor-grid {
        grid-template-columns: 1fr;
      }

      .step-card {
        padding: 16px 18px;
      }
    }
  </style>
</head>

<body>

  <div class="container">

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê HEADER ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <header class="anim d1">
      <div class="logo">Context<span>Map</span></div>
      <div class="header-sub">alphagenome-fm</div>
      <div class="meta-bar">
        <span class="meta-pill">üìÖ Updated Feb 21, 2026</span>
        <span class="meta-pill">üìÇ 3 sessions</span>
        <span class="meta-pill">üî¢ 10 steps</span>
      </div>
    </header>

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê SESSION NARRATIVE ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <section id="narrative" class="anim d2">
      <div class="section-label">Session Narrative</div>
      <div class="card">

        <div class="narrative-session">
          <div class="narrative-session-label">Session 3 ¬∑ Feb 21</div>
          <ul class="narrative-list">
            <li>Fine-tuned AlphaGenome on ClinVar pathogenicity prediction ‚Äî AUROC 0.91 on held-out chr8</li>
            <li>Investigated attention heads; discovered head 7 in layer 4 strongly tracks splice donor/acceptor motifs
            </li>
            <li>Implemented gradient-weighted attribution to visualize per-nucleotide importance scores</li>
          </ul>
        </div>

        <div class="narrative-session">
          <div class="narrative-session-label">Session 2 ¬∑ Feb 20</div>
          <ul class="narrative-list">
            <li>Resolved OOM during training by switching from full attention to FlashAttention-2 and gradient
              checkpointing</li>
            <li>Replaced naive 1-mer tokenization with BPE trained on hg38 ‚Äî vocabulary of 4,096 tokens, ~3.2√ó
              compression</li>
            <li>Trained 150M-param model on chr1‚Äìchr7 for 50k steps; validated on chr8 with perplexity 4.21</li>
          </ul>
        </div>

        <div class="narrative-session">
          <div class="narrative-session-label">Session 1 ¬∑ Feb 19</div>
          <ul class="narrative-list">
            <li>Scaffolded AlphaGenome project: data loaders for hg38 FASTA via <code>pysam</code>, configurable context
              windows</li>
            <li>Implemented initial Transformer encoder (6 layers, 512 hidden, 8 heads) with rotary positional
              embeddings</li>
            <li>Built masked language modeling (MLM) objective ‚Äî 15% random nucleotide masking on 2 kb windows</li>
            <li>First training run OOM'd on A100 at batch size 64 with 4 kb context ‚Äî deferred to Session 2</li>
          </ul>
        </div>

      </div>
    </section>

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê CONTEXT ANCHOR ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <section id="anchor" class="anim d3">
      <div class="section-label">Where We Left Off</div>
      <div class="anchor-grid">
        <div class="anchor-item">
          <div class="anchor-icon">üìç</div>
          <div>
            <div class="anchor-label">Last Working On</div>
            <div class="anchor-text">Gradient-weighted attribution maps in <code>interpret/attribution.py</code> ‚Äî
              visualizing per-nucleotide importance for ClinVar variant predictions</div>
          </div>
        </div>
        <div class="anchor-item">
          <div class="anchor-icon">‚úÖ</div>
          <div>
            <div class="anchor-label">Current State</div>
            <div class="anchor-text">150M-param model pretrained (perplexity 4.21), fine-tuned on ClinVar pathogenicity
              (AUROC 0.91 on chr8)</div>
          </div>
        </div>
        <div class="anchor-item">
          <div class="anchor-icon">üîú</div>
          <div>
            <div class="anchor-label">Next Up</div>
            <div class="anchor-text">Benchmark against Enformer and Nucleotide Transformer on CADD score prediction;
              evaluate on non-coding regulatory variants</div>
          </div>
        </div>
        <div class="anchor-item">
          <div class="anchor-icon">‚ö†Ô∏è</div>
          <div>
            <div class="anchor-label">Open Concern</div>
            <div class="anchor-text">BPE tokenizer may split biologically meaningful motifs (TATA box, splice sites);
              consider motif-aware tokenization</div>
          </div>
        </div>
        <div class="anchor-item full-width">
          <div class="anchor-icon">üß¨</div>
          <div>
            <div class="anchor-label">Key Decision</div>
            <div class="anchor-text">Chose BPE tokenization (4,096 vocab) over fixed k-mer ‚Äî BPE learns biologically
              adaptive token boundaries and achieves 3.2√ó compression over character-level, reducing effective sequence
              length from 4,096 nt to ~1,280 tokens</div>
          </div>
        </div>
      </div>
    </section>

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê EVOLUTION TIMELINE ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <section id="timeline" class="anim d4">
      <div class="section-label">Evolution Timeline</div>

      <div class="timeline">

        <!-- ‚îÄ‚îÄ‚îÄ‚îÄ Session 3 ‚îÄ‚îÄ‚îÄ‚îÄ -->
        <div class="session-divider">
          <span class="session-divider-label">Session 3 ¬∑ Feb 21, 2026</span>
        </div>

        <!-- Step 8 -->
        <div class="step-card anim d5" onclick="toggle(this)">
          <div class="step-dot success"></div>
          <div class="step-header">
            <span class="step-num">#8</span>
            <span class="step-title">Fine-tune on ClinVar pathogenicity</span>
            <span class="badge success">Success</span>
          </div>
          <div class="step-preview">Added classification head on pretrained encoder; fine-tuned on ClinVar SNVs with
            chr8 held out ‚Äî AUROC 0.91</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>With pretraining converged, wanted to evaluate the model's learned representations on a real
                  downstream task</li>
                <li>Chose ClinVar pathogenicity classification as first benchmark ‚Äî well-studied, clinically relevant,
                  clear labels</li>
                <li>Needed to build a fine-tuning pipeline: freeze encoder for first 5 epochs, then unfreeze with lower
                  LR</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Expected</div>
              <ul class="detail-bullets">
                <li>Binary classification (pathogenic vs. benign) for single nucleotide variants</li>
                <li>Target AUROC > 0.85 to be competitive with existing genomic language models</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Created <code>tasks/clinvar.py</code> with a linear classification head on the [CLS]-equivalent
                  embedding</li>
                <li>Extracted ¬±1 kb flanking context for each variant from hg38; ref and alt sequences as paired inputs
                </li>
                <li>Two-phase training: 5 epochs frozen encoder (LR 1e-3), then 15 epochs full fine-tune (LR 5e-5)</li>
                <li>Achieved AUROC 0.91 on held-out chr8 ‚Äî above initial target; precision 0.87, recall 0.84</li>
                <li>Noted class imbalance (3:1 benign:pathogenic); applied focal loss which improved recall from 0.79 to
                  0.84</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">tasks/clinvar.py</span>
                <span class="artifact">data/clinvar_snvs.tsv</span>
                <span class="artifact">configs/finetune_clinvar.yaml</span>
                <span class="artifact">train_finetune.py</span>
              </div>
            </div>
          </div>
        </div>

        <div class="transition anim d5">
          <span class="transition-text">Strong classification results raised the question: what is the model actually
            learning? Decided to inspect attention patterns for biological interpretability</span>
        </div>

        <!-- Step 9 -->
        <div class="step-card anim d6" onclick="toggle(this)">
          <div class="step-dot success"></div>
          <div class="step-header">
            <span class="step-num">#9</span>
            <span class="step-title">Analyze attention heads for biological motifs</span>
            <span class="badge success">Success</span>
          </div>
          <div class="step-preview">Head 7 in layer 4 strongly attends to splice donor/acceptor motifs (GT‚ÄìAG); head 2
            in layer 6 tracks TATA-like promoter elements</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>Wanted to validate that high AUROC reflects biologically meaningful features, not just sequence
                  composition bias</li>
                <li>Planned to extract attention matrices from each head and correlate with known regulatory annotations
                  from ENCODE</li>
                <li>Focus on splice sites and promoter motifs as they are well-characterized ground truth</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Expected</div>
              <ul class="detail-bullets">
                <li>At least some attention heads should show enrichment at known functional motifs</li>
                <li>If no heads correlate, the model may be overfitting on trivial features</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Extracted attention weights from all 8 heads √ó 6 layers across 500 ClinVar variant regions</li>
                <li>Head L4-H7 shows striking enrichment at canonical splice donor (<code>GT</code>) and acceptor
                  (<code>AG</code>) dinucleotides ‚Äî Pearson r=0.72 with MaxEntScan scores</li>
                <li>Head L6-H2 shows weak but consistent enrichment at TATA-box positions in promoter-proximal regions
                </li>
                <li>Remaining heads appear to encode positional or GC-content features ‚Äî no clear biological motif</li>
                <li>Saved visualizations using matplotlib heatmaps overlaid on sequence logos</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">interpret/attention_analysis.py</span>
                <span class="artifact">notebooks/attention_motifs.ipynb</span>
                <span class="artifact">figures/head_L4H7_splice.png</span>
              </div>
            </div>
          </div>
        </div>

        <div class="transition anim d6">
          <span class="transition-text">Attention head analysis confirmed biological learning; wanted finer-grained,
            per-nucleotide importance for individual variant predictions</span>
        </div>

        <!-- Step 10 -->
        <div class="step-card anim d7" onclick="toggle(this)">
          <div class="step-dot in_progress"></div>
          <div class="step-header">
            <span class="step-num">#10</span>
            <span class="step-title">Implement gradient-weighted attribution</span>
            <span class="badge in_progress">In Progress</span>
          </div>
          <div class="step-preview">Integrated gradient √ó input method for per-nucleotide importance; working on
            comparing against ISM (in-silico mutagenesis) as ground truth</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>Attention maps show head-level patterns, but clinicians need per-nucleotide importance for a
                  specific variant</li>
                <li>Planned two methods: gradient √ó input (fast) and integrated gradients (more accurate)</li>
                <li>Needed to validate attributions against ISM (exhaustive single-nt mutation scan) as gold standard
                </li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Expected</div>
              <ul class="detail-bullets">
                <li>Attribution scores should peak at the variant position and flanking regulatory elements</li>
                <li>Correlation with ISM scores should be r > 0.6 if attributions are trustworthy</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Implemented <code>gradient_x_input()</code> ‚Äî fast, runs in ~200ms per variant</li>
                <li>Integrated gradients implemented but slow (~8s per variant with 50 interpolation steps)</li>
                <li>Preliminary comparison on 20 variants: gradient √ó input vs. ISM correlation r=0.58 ‚Äî slightly below
                  target</li>
                <li><strong>Still running</strong> full ISM benchmark on 500 variants (estimated 6h on A100)</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">interpret/attribution.py</span>
                <span class="artifact">interpret/ism.py</span>
                <span class="artifact">scripts/run_ism_benchmark.sh</span>
              </div>
            </div>
          </div>
        </div>

        <!-- ‚îÄ‚îÄ‚îÄ‚îÄ Session 2 ‚îÄ‚îÄ‚îÄ‚îÄ -->
        <div class="session-divider" style="margin-top: 36px;">
          <span class="session-divider-label">Session 2 ¬∑ Feb 20, 2026</span>
        </div>

        <!-- Step 5 -->
        <div class="step-card anim d8" onclick="toggle(this)">
          <div class="step-dot success"></div>
          <div class="step-header">
            <span class="step-num">#5</span>
            <span class="step-title">Fix OOM with FlashAttention-2 + gradient checkpointing</span>
            <span class="badge success">Success</span>
          </div>
          <div class="step-preview">OOM at batch 64 / 4 kb context on A100; FlashAttention-2 + gradient checkpointing
            reduced peak VRAM from 78 GB to 31 GB</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>Session 1 ended with OOM crash at batch_size=64 on 4 kb context windows on A100 80 GB</li>
                <li>Profiling with <code>torch.cuda.memory_summary()</code> showed attention matrices consuming ~42 GB
                  for full O(n¬≤) attention</li>
                <li>Two strategies: (1) FlashAttention-2 for memory-efficient attention, (2) gradient checkpointing to
                  trade compute for memory</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Installed <code>flash-attn==2.5.6</code>; replaced <code>nn.MultiheadAttention</code> with
                  <code>flash_attn.flash_attn_func</code></li>
                <li>Enabled <code>torch.utils.checkpoint.checkpoint()</code> on every other transformer block</li>
                <li>Peak VRAM dropped from ~78 GB to ~31 GB; batch_size=64 now fits comfortably on A100 80 GB</li>
                <li>Training throughput decreased ~15% due to checkpointing recomputation ‚Äî acceptable trade-off</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">model/transformer.py</span>
                <span class="artifact">requirements.txt</span>
                <span class="artifact">configs/train_pretrain.yaml</span>
              </div>
            </div>
          </div>
        </div>

        <div class="transition anim d8">
          <span class="transition-text">OOM resolved ‚Äî before launching full pretraining, reconsidered whether naive
            character-level tokenization was optimal for long genomic sequences</span>
        </div>

        <!-- Step 6 -->
        <div class="step-card anim d9" onclick="toggle(this)">
          <div class="step-dot success"></div>
          <div class="step-header">
            <span class="step-num">#6</span>
            <span class="step-title">BPE tokenizer trained on hg38 genome</span>
            <span class="badge success">Success</span>
          </div>
          <div class="step-preview">Replaced 1-mer tokenization with BPE (vocab 4,096) trained on hg38 ‚Äî 3.2√ó
            compression, reducing 4 kb sequences to ~1,280 tokens</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>Character-level tokenization (A/C/G/T) creates very long sequences (4,096 tokens for 4 kb) ‚Äî
                  expensive even with FlashAttention</li>
                <li>Hypothesis: BPE can learn biologically meaningful subword units (common k-mers, repeat elements)
                  while compressing sequence length</li>
                <li>Considered alternatives: fixed 6-mer (4,096 vocab) vs. BPE ‚Äî BPE can adapt to genome-specific
                  frequency distributions</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Trained BPE tokenizer using <code>tokenizers</code> library on chr1‚Äìchr22 of hg38 (3.1 Gbp)</li>
                <li>Final vocabulary: 4,096 tokens; average compression ratio 3.2√ó (4,096 nt ‚Üí ~1,280 tokens)</li>
                <li>Inspected top tokens: many correspond to common dinucleotide repeats (CpG, CA/TG), Alu elements, and
                  poly-A stretches</li>
                <li><strong>Concern noted:</strong> some canonical splice motifs (GT-AG) get split across token
                  boundaries ‚Äî may need motif-aware constraints</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">tokenizer/train_bpe.py</span>
                <span class="artifact">tokenizer/bpe_4096.json</span>
                <span class="artifact">data/genome_loader.py</span>
              </div>
            </div>
          </div>
        </div>

        <div class="transition anim d9">
          <span class="transition-text">Tokenizer ready and memory issues resolved ‚Äî now had all components to launch
            the full pretraining run</span>
        </div>

        <!-- Step 7 -->
        <div class="step-card anim d10" onclick="toggle(this)">
          <div class="step-dot success"></div>
          <div class="step-header">
            <span class="step-num">#7</span>
            <span class="step-title">Pretrain 150M model on chr1‚Äìchr7 (50k steps)</span>
            <span class="badge success">Success</span>
          </div>
          <div class="step-preview">50k steps of MLM pretraining on chromosomes 1‚Äì7; validation perplexity on chr8
            converged to 4.21</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>All components ready: FlashAttention model, BPE tokenizer, data loaders ‚Äî time for full pretraining
                </li>
                <li>Used chr1‚Äìchr7 as training set (~1.3 Gbp), chr8 as validation (~145 Mbp), chr9 held out for final
                  test</li>
                <li>Target: perplexity < 5.0 on validation, competitive with Nucleotide Transformer (reported ~4.5 at
                    150M scale)</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Training completed in ~14 hours on 4√ó A100 with DeepSpeed ZeRO-2</li>
                <li>Final validation perplexity: 4.21 ‚Äî better than initial target, likely due to BPE compression
                  reducing effective sequence complexity</li>
                <li>Loss curves smooth; no signs of overfitting (train perplexity 3.94 vs. val 4.21)</li>
                <li>Saved checkpoints every 10k steps to <code>checkpoints/pretrain/</code></li>
                <li>WandB run logged: learning rate schedule (linear warmup 2k steps, cosine decay to 1e-5)</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">train_pretrain.py</span>
                <span class="artifact">configs/train_pretrain.yaml</span>
                <span class="artifact">checkpoints/pretrain/step_50000/</span>
                <span class="artifact">scripts/launch_distributed.sh</span>
              </div>
            </div>
          </div>
        </div>

        <!-- ‚îÄ‚îÄ‚îÄ‚îÄ Session 1 ‚îÄ‚îÄ‚îÄ‚îÄ -->
        <div class="session-divider" style="margin-top: 36px;">
          <span class="session-divider-label">Session 1 ¬∑ Feb 19, 2026</span>
        </div>

        <!-- Step 1 -->
        <div class="step-card anim d11" onclick="toggle(this)">
          <div class="step-dot success"></div>
          <div class="step-header">
            <span class="step-num">#1</span>
            <span class="step-title">Scaffold project + hg38 data loaders</span>
            <span class="badge success">Success</span>
          </div>
          <div class="step-preview">Set up AlphaGenome project structure; built FASTA data loader with pysam for
            streaming hg38 windows with configurable context length</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>Starting a new genomic foundation model project inspired by Nucleotide Transformer and DNABERT-2
                </li>
                <li>Needed efficient data pipeline for sampling random genomic windows from hg38 reference genome</li>
                <li>Required: streaming reads (genome too large to load in memory), configurable window size, N-masking
                  for assembly gaps</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Created project structure: <code>model/</code>, <code>data/</code>, <code>tokenizer/</code>,
                  <code>tasks/</code>, <code>configs/</code>, <code>scripts/</code></li>
                <li>Built <code>GenomeDataset</code> class using <code>pysam.FastaFile</code> for random-access reads
                  from indexed FASTA</li>
                <li>Supports configurable window sizes (512 nt to 8 kb), chromosome filtering, and N-base exclusion</li>
                <li>DataLoader with 8 workers achieves ~12k windows/sec throughput on NVMe SSD</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">data/genome_loader.py</span>
                <span class="artifact">data/utils.py</span>
                <span class="artifact">configs/data.yaml</span>
                <span class="artifact">requirements.txt</span>
              </div>
            </div>
          </div>
        </div>

        <div class="transition anim d11">
          <span class="transition-text">Data pipeline working ‚Äî moved on to defining the core model architecture</span>
        </div>

        <!-- Step 2 -->
        <div class="step-card anim d12" onclick="toggle(this)">
          <div class="step-dot success"></div>
          <div class="step-header">
            <span class="step-num">#2</span>
            <span class="step-title">Implement Transformer encoder with RoPE</span>
            <span class="badge success">Success</span>
          </div>
          <div class="step-preview">6-layer Transformer encoder (512 dim, 8 heads) with rotary positional embeddings for
            length generalization</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>Chose Transformer encoder (BERT-style) over decoder ‚Äî MLM objective better suited for bidirectional
                  genomic context</li>
                <li>Used rotary positional embeddings (RoPE) instead of absolute ‚Äî better extrapolation to longer
                  sequences at inference</li>
                <li>Starting small (6 layers, 512 dim, ~25M params) for rapid iteration before scaling up</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Implemented custom <code>GenomicTransformerEncoder</code> with RoPE in
                  <code>model/transformer.py</code></li>
                <li>Added pre-norm (LayerNorm before attention/FFN) for training stability</li>
                <li>Unit tests pass: forward pass on batch of 32 √ó 2,048 tokens in 45ms on A100</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">model/transformer.py</span>
                <span class="artifact">model/rope.py</span>
                <span class="artifact">tests/test_model.py</span>
              </div>
            </div>
          </div>
        </div>

        <div class="transition anim d12">
          <span class="transition-text">Architecture defined ‚Äî needed to implement the self-supervised training
            objective</span>
        </div>

        <!-- Step 3 -->
        <div class="step-card anim d13" onclick="toggle(this)">
          <div class="step-dot success"></div>
          <div class="step-header">
            <span class="step-num">#3</span>
            <span class="step-title">Build MLM training objective</span>
            <span class="badge success">Success</span>
          </div>
          <div class="step-preview">15% random nucleotide masking with 80/10/10 mask/random/keep strategy on 2 kb
            windows; cross-entropy loss on masked positions only</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>Standard masked language modeling: mask 15% of input nucleotides, train model to predict the
                  originals</li>
                <li>Used 80/10/10 strategy (80% [MASK] token, 10% random nucleotide, 10% unchanged) following BERT</li>
                <li>Considered span masking (mask contiguous k-mers) but deferred for simplicity in v1</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Implemented <code>MLMCollator</code> in <code>data/collator.py</code> ‚Äî handles dynamic masking per
                  batch</li>
                <li>Loss computed only on masked positions using <code>CrossEntropyLoss(ignore_index=-100)</code></li>
                <li>Verified: random baseline achieves ~1.39 nats loss (‚àíln(1/4)); model should converge well below this
                </li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">data/collator.py</span>
                <span class="artifact">train_pretrain.py</span>
                <span class="artifact">tests/test_collator.py</span>
              </div>
            </div>
          </div>
        </div>

        <div class="transition anim d13">
          <span class="transition-text">All components in place ‚Äî attempted first end-to-end training run to validate
            the pipeline</span>
        </div>

        <!-- Step 4 -->
        <div class="step-card anim d14" onclick="toggle(this)">
          <div class="step-dot failed"></div>
          <div class="step-header">
            <span class="step-num">#4</span>
            <span class="step-title">First training run ‚Äî OOM crash</span>
            <span class="badge failed">Failed</span>
          </div>
          <div class="step-preview">Training crashed with CUDA OOM at batch_size=64, context=4096 nt on A100 80 GB ‚Äî
            full attention O(n¬≤) too expensive</div>
          <div class="step-detail">
            <div class="detail-section">
              <div class="detail-heading">Intent</div>
              <ul class="detail-bullets">
                <li>End-to-end smoke test: data loader ‚Üí tokenizer ‚Üí model ‚Üí MLM loss ‚Üí backward pass</li>
                <li>Wanted to verify the full pipeline works before committing to long training runs</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Result</div>
              <ul class="detail-bullets">
                <li>Forward pass succeeded; loss computed correctly (initial loss ~1.38, close to random baseline as
                  expected)</li>
                <li>OOM on <code>loss.backward()</code> at batch_size=64, sequence_length=4096 ‚Äî peaked at ~78 GB</li>
                <li>Profiling showed attention matrices account for ~42 GB (self-attention is O(n¬≤) in memory)</li>
                <li>Batch_size=8 works but too small for stable training ‚Äî need FlashAttention or gradient checkpointing
                </li>
                <li>Deferred memory optimization to next session</li>
              </ul>
            </div>
            <div class="detail-section">
              <div class="detail-heading">Artifacts</div>
              <div class="artifacts-row">
                <span class="artifact">train_pretrain.py</span>
                <span class="artifact">logs/oom_profile.txt</span>
              </div>
            </div>
          </div>
        </div>

      </div>
    </section>

    <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê OPEN THREADS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
    <section id="threads" class="anim d14">
      <div class="section-label">Open Threads</div>
      <div class="card">
        <div class="thread">
          <div class="thread-icon">üß™</div>
          <div>
            <div class="thread-title">CADD Score Benchmark</div>
            <div class="thread-desc">Need to benchmark variant effect prediction against CADD v1.7 and Enformer on
              non-coding regulatory variants.</div>
            <div class="thread-next">‚Üí Download CADD annotations, implement evaluation script, compare AUROC/AUPRC</div>
          </div>
        </div>
        <div class="thread">
          <div class="thread-icon">üî§</div>
          <div>
            <div class="thread-title">Motif-Aware Tokenization</div>
            <div class="thread-desc">BPE tokenizer sometimes splits known biological motifs (TATA box, splice sites).
              Consider adding motif constraints or a hybrid tokenizer.</div>
            <div class="thread-next">‚Üí Compile JASPAR motif database, add "never-split" rules to BPE, retrain tokenizer
            </div>
          </div>
        </div>
        <div class="thread">
          <div class="thread-icon">üìà</div>
          <div>
            <div class="thread-title">Scale to 500M Parameters</div>
            <div class="thread-desc">Current 150M model shows promising results. Literature suggests genomic LMs benefit
              significantly from scaling (Nucleotide Transformer: 2.5B).</div>
            <div class="thread-next">‚Üí Design 500M config (12 layers, 1024 dim, 16 heads), estimate compute budget on 8√ó
              A100 node</div>
          </div>
        </div>
        <div class="thread">
          <div class="thread-icon">üß¨</div>
          <div>
            <div class="thread-title">Enhancer Activity Prediction Task</div>
            <div class="thread-desc">ENCODE STARR-seq data provides quantitative enhancer activity labels. Good second
              fine-tuning task to test regression capabilities.</div>
            <div class="thread-next">‚Üí Process STARR-seq data from ENCODE, build regression head, fine-tune and evaluate
              Pearson r</div>
          </div>
        </div>
      </div>
    </section>

    <footer>
      <p>Generated by ContextMap ¬∑ Feb 21, 2026</p>
    </footer>

  </div>

  <script>
    function toggle(card) {
      var d = card.querySelector('.step-detail');
      var p = card.querySelector('.step-preview');
      if (!d) return;
      var open = d.classList.contains('open');
      d.classList.toggle('open', !open);
      if (p) p.classList.toggle('hidden', !open);
    }
  </script>

</body>

</html>